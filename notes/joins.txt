Here are some notes on making 'join c r s' faster than the naive
implementation,

 cartesianProduct r s >>= select c

First, even within 'join' itself we can exploit some of the query
optimization techniques mentioned in the Wikipedia article on
Relational Algebra. By splitting the condition 'c' into a conjunction

 c_r && c_s && c_rs

where

 c_r  uses attributes from r only
 c_s  uses attributes from s only
 c_rs uses attributes from both r and s

we can then implement 'join' as

 cartesianProduct r' s' >>= select c_rs
 where r' = select c_r r
       s' = select c_s s

The idea is that r' and s' will never be larger than r and s, and may
be much smaller, so the cartesian product will be smaller.

Speeding up joins where the condition is an attribute equality
--------------------------------------------------------------

Second, I think we might be able to do better than

 cartesianProduct r' s' >>= select c_rs

for certain kinds of c_rs. In particular, let's suppose that c_rs has
the form

 a_r == a_s

where a_r and a_s are attributes of r and s, respectively.

Suppose that we construct a map for 's' from values of 'a_s' to lists
of tuples where 'a_s' has that value. In other words, on the fly we
build an index for 's' keyed by the value of 'a_s'. Call this index
'i_a_s'.

We can then build the tuples for the join with condition

 a_r == a_s

by iterating through the tuples of 'r' and for each tuple 't_r'
joining with just the tuples in

 i_a_s ! t_r[a_r]

Can we expect this to be faster than the naive implementation? Let

 n = |r|, the number of tuples in r
 m = |s|, the number of tuples in s

and

 q = |join c r s|, the number of tuples in the result.

We'll count two fundamental operations: joining individual tuples, and
performing comparisons on attribute values. For the naive
implementation, we have

 n*m  tuple joins

 n*m  attribute comparisons

since we compute all possible tuple joins and then perform a test on
each joined tuple to filter out the ones we don't want.

For the method where we build an index, we get

  O(m log m) attribute comparisons to build the index i_a_s

  O(n log m) attribute comparisons to do the lookups i_a_s ! t_r[a_r]

  q tuple joins

for a total of

  (n + m) log m  comparisons

  q tuple joins

Note that we perform the minimum possible number of tuple joins, and
we don't discard any of the joined tuples. Except for very small
values of 'n' and 'm', we'll also perform fewer attribute comparisons.

Instead of indexing 's' by the values of 'a_s', we could index 'r' by
the values of 'a_r'. This will result in

  (n + m) log n  comparisons

  q tuple joins

This means that to minimize the number of comparisons we should index
the smaller relation.

Speeding up complex joins
-------------------------

Now, let's suppose that 'c_rs' is more complex than a single equality
on attributes. If it's of the form

 a_r == a_s && d_rs

then we have two strategies we can take. We can compute joins for the
sub-conditions separately, and then take their intersection, or we can
compute the join for 'a_r == a_s', and then perform a 'select d_rs' on
the result.

Let's look at the problem a bit more generally. We can replace the
logical connectives in join conditions with operations on whole
relations. In fact, we can completely remove 'join' operations, but
using the default form

 join c r s = cartesianProduct r s >>= select c

only as a last resort.

 1. join true r s == cartesianProduct r s

 2. join false r s == empty (sig r)

 3. join (not c) r s == (cartesianProduct r s `difference` join c r s)

    this identity isn't really useful going left to right, but it
    might be useful going right to left, or for a speculative
    decomposition of a query.

 4. join (c || d) r s == join c r s `union` join d r s

 5. join (c && d) r s == join c r s `intersection` join d r s

 6. join (a_r `op` A) r s == cartesianProduct (select (a_r `op` A) r) s
    join (A `op` a_r) r s == cartesianProduct (select (A `op` a_r) r) s

    where `op` is one of '<', '==' or '>'

 7. join (a_s `op` A) r s == cartesianProduct r (select (a_s `op` A) s)
    join (A `op` a_s) r s == cartesianProduct r (select (A `op` a_s) s)

    where `op` is one of '<', '==' or '>'

 8. join (a_r == a_s) r s == special handling with index

 9. join (a_r > a_s) r s == special handling with index (see below)

10. join (a_r < a_s) r s == special handling with index (see below)

11. join c r s = cartesianProduct r s >>= select c

    for any other kind of condition 'c'

For cases (9) and (10), the index may be such that we can easily find
all the entries where the key is less than or greater than a
particular value. If this is the case, then indexing the smaller
relation will likely be a benefit there too.

The Data.Map.split function turns out to be just what we need!

 Data.Map.split :: (Ord k) => k -> Map k a -> (Map k a, Map k a)

 split k m

returns an ordered pair containing two sub-maps of m, the first where
all the keys are less than 'k', and the second where all the keys are
greater than 'k'. This is exactly what we need for special handling.

After we have decomposed all the 'join' operations, we may need to
reduce the size of some of the Cartesian products. Our main tool for
doing this will be some identities for the interaction between
Cartesian product and other set operations.

12. cartesianProduct r s `intersection` cartesianProduct t u

      == cartesianProduct (r `intersection` t) (s `intersection` u)

13. select c r `intersection` r == select c r

14. select c r `union` r == r

15. select c r `intersection` select d r
      == select (c && d) r
      == select c (select d r)
      == select d (select c r)

16. select c r `union` select d r == select (c || d) r

This set of identities is incomplete. It's time to dig up some papers
on relational query optimization.
